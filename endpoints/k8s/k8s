#!/usr/bin/env bash
# vim: autoindent tabstop=4 shiftwidth=4 expandtab softtabstop=4 filetype=bash

# This script implements the 'k8s' endpoint for rickshaw.  It runs 1 or more
# clients (and no servers, yet) for as many benchmark interations/samples as required
# for a single invocation of rickshaw.  Like all enpoints, this is meant to be used
# with other endpoints for creating multi-cloud tests.
#
# Usage:
# local [--validate] --endpoint-opts=host=<host>,user=<user>,client:n-m,o-p,server:n-m,o-p 
#                    --run-id <id> --base-run-dir --image <location>
#                    --roadblock-server <host> --roadblock-id <id> --roadblock-passwd=<passwd>
#
# If --validate is used all options after client/server will be ignored
#
# TODO: This endpoint script was copied from 'local' endpoint and has some common function.
#       Some of that code could probably be consolidated into a library or utilities.
#       Utilities may work better since other endpoint may be written in a different language.
# TODO: There are a significant number of features we need to implement for pod preferences:
#       - node placement for pods/containers
#       - multus support
#       - pod requests and limits
#       - running benchmark servers and setting up the service and router
#       - containers/pod options
#       - implement tool execution outside the client/server pods (on workers and masters with
#         privileged pods)
#       - collecting information of pod creation and execution
#       - implementing a system info collection of a k8s cluster
#       - using a user-definable container registry for container image sourcing
#         - this is hard-coded right now
#         - rickshaw needs changes to publish locally built images (from workshop) to the user's
#           registry
#         - all endpoint scripts will need to make this change when rickshaw supports this
#
# All of the functions that a client-server-script performs works in this endpoint, such as:
# - benchmark iteration/sample execution
# - using a container image which has the required software
# - tool execution
# - synchronization of execution
# - sending tool and benchmark data back to the controller (where this endpoint script runs)

# Source the base file for common functions and config
this_endpoint_dir=$(dirname `readlink -e $0` | sed -e 'sX/binXX')
endpoint_base_dir=$(cd $this_endpoint_dir >/dev/null && cd .. && /bin/pwd)
if [ -e "$endpoint_base_dir/base" ]; then
    . "$endpoint_base_dir/base"
else
    echo "Could not find endpoint source file "$endpoint_base_dir/base", exiting"
    exit 1
    exit
fi
endpoint_name="k8s"
# TODO: instead of using a prefix in the pods' names, use a unique k8s project
pod_prefix="rickshaw"
userenv="rhubi8"
hostNetwork="0"
securityContext=""
resources=""
declare -A nodeSelector

function endpoint_k8s_test_stop() {
    local msgs_dir="$1"; shift
    local test_id="$1"; shift
    echo "Running endpoint_k8s_test_stop"

    echo "Endpoints:"
    ssh $k8s_user@$k8s_host kubectl get endpoints -o yaml
    endpoints=`ssh $k8s_user@$k8s_host kubectl get endpoints | grep rickshaw | awk '{print $1}'`
    echo "Endpoints to delete:"
    echo $endpoints
    ssh $k8s_user@$k8s_host kubectl delete endpoints $endpoints

    echo "Services:"
    ssh $k8s_user@$k8s_host kubectl get svc -o yaml
    services=`ssh $k8s_user@$k8s_host kubectl get svc | grep rickshaw | awk '{print $1}'`
    echo "Services to delete:"
    echo $services
    ssh $k8s_user@$k8s_host kubectl delete svc $services
}

function endpoint_k8s_test_start() {
    # This function runs right after a server starts any service and right before a client starts
    # and tries to contect the server's service.  The purpose of this function is to do any
    # work which ensures the client can contact the server.  In some cases there may be nothing
    # to do.  Regardless of the work, the endpoint needs to relay what IP & ports the client
    # needs to use in order to reach the server.  In some cases that may be the information the
    # server has provided to the endpoint, or this information has changed because the endpoint
    # created some sort of proxy to reach the server.
    #
    # In the case of the k8s endpoint, there are two possible actions, and this depends on where
    # the client is in relation to the server.  If the client is within the same k8s cluster,
    # we only need to create a k8s-service, so the client can use an IP which is more persistent
    # than a pod's IP (this allows pods to come and go while keeping the same IP).  This is not
    # absolutely necessary for client-server benchnarks, but it is a best practice for cloud-native
    # aps, so we do it anyway.  If the client is not in the k8s cluster, then we must assume 
    # it does not have direct access to the pod cluster network, and some form of 'ingress' must
    # be set up.  Currently, this endpoint implements 'NodePort', which provides a port for
    # the service which can be accessed on any of the cluster's nodes.  However, we provide the
    # IP address of the node which happens to host the server pod.
    local msgs_dir="$1"; shift
    local test_id="$1"; shift
    local tx_msgs_dir="$1"; shift
    echo "Running endpoint_k8s_test_start"
    # Creating any service or ingress only works if any servers provided information about its
    # IP and ports.
    local this_msg_file="$msgs_dir/$test_id:endpoint-start.json"
    if [ -e $this_msg_file ]; then
        echo "Found $this_msg_file"
        # Extract the cs-label (server-n, client-y) and the ports this benchmark is using
        # server-1 30002 30003
        cat $this_msg_file | jq -r '.received[] | if .payload.message.command == "user-object" and .payload.message."user-object".svc.ports then [ .payload.sender.id, .payload.message."user-object".svc.ports ] | flatten | tostring   else null end' | grep -v null | sed -e 's/"//g' -e 's/\[//' -e 's/\]//' -e 's/,/ /g' >"$endpoint_run_dir/ports.txt"
	    while read -u 9 line; do
            # Wether or not the client is hosted in this cluster, a service will be created
            # for the server, and an endpoint will be created to ensure the service forwards
            # connections to exactly the pod we want.
            echo "line: $line"
	        local name=`echo $line | awk '{print $1}'`
	        local ports=`echo $line | sed -e s/^$name//`
	        local svc_json=$endpoint_run_dir/$name-svc.json
	        echo name: $name
	        echo ports: $ports
	        echo '{' >$svc_json
            echo '    "apiVersion": "v1",' >>$svc_json
            echo '    "kind": "Service",' >>$svc_json
            echo '    "metadata": {' >>$svc_json
            echo '        "name": "rickshaw-'$name'"' >>$svc_json
            echo '    },' >>$svc_json
            echo '    "spec": {' >>$svc_json
            echo '        "ports": [' >>$svc_json
	        local count=1
	        local port_list=""
	        for port in $ports; do
		        if [ $count -gt 1 ]; then
                    port_list+=", $port"
                    echo '            ,{' >>$svc_json
		        else
                    port_list="$port"
                    echo '            {' >>$svc_json
		        fi
                echo '                "name": "port-'$port'",' >>$svc_json
                echo '                "port": '$port',' >>$svc_json
                # TODO: Support UDP
                echo '                "protocol": "TCP",' >>$svc_json
                echo '                "targetPort": '$port >>$svc_json
                echo '            }' >>$svc_json
		        let count=$count+1
            done
            echo '        ]' >>$svc_json
            echo '    }' >>$svc_json
            echo '}' >>$svc_json
            cat "$svc_json" | ssh $k8s_user@$k8s_host "kubectl create -f -" >"$endpoint_run_dir/create-svc-$name.txt"
            # Debug info
            ssh $k8s_user@$k8s_host "kubectl get svc/rickshaw-$name -o json" >"$endpoint_run_dir/get-svc-$name.json"
            # Now that the service has been created, we can get the IP to contact the benchmark server
            local svc_ip=`ssh $k8s_user@$k8s_host "kubectl get svc/rickshaw-$name -o json | jq -r .spec.clusterIP"`
            # Instead of relying on k8s to make an association between the service and the pod, we explicitly
            # connect the two by creating the endpoint, linking the service to the IP of the server pod
	        local svc_endp_json=$endpoint_run_dir/$name-endpoint.json
            # While the server message does provide the IP, we just use the information we have from k8s
	        local pod_ip=`ssh $k8s_user@$k8s_host "oc get pod/rickshaw-$name -o wide" | grep rickshaw | awk '{print $6}'`
	        echo '{' >$svc_endp_json
            echo '    "apiVersion": "v1",' >>$svc_endp_json
            echo '    "kind": "Endpoints",' >>$svc_endp_json
            echo '    "metadata": {' >>$svc_endp_json
            echo '        "name": "rickshaw-'$name'"' >>$svc_endp_json
            echo '    },' >>$svc_endp_json
            echo '    "subsets": [{' >>$svc_endp_json
            echo '        "addresses": [ { "ip": "'$pod_ip'" } ],' >>$svc_endp_json
            echo '        "ports": [' >>$svc_endp_json
	        local count=1
	        for port in $ports; do
		        if [ $count -gt 1 ]; then
                    echo '            ,{' >>$svc_endp_json
		        else
                    echo '            {' >>$svc_endp_json
		        fi
                    echo '                "name": "port-'$port'", "port": '$port'}' >>$svc_endp_json
		        let count=$count+1
	        done
            echo '        ]' >>$svc_endp_json
            echo '    }]' >>$svc_endp_json
            echo '}' >>$svc_endp_json
            cat "$svc_endp_json" | ssh $k8s_user@$k8s_host "kubectl create -f -" >"$endpoint_run_dir/create-svc-endp-$name.txt"


            # TODO: determine if client is outside cluster
            local client_outside_cluster="false"
            if [ "$client_outside_cluster" == "true" ]; then
                # We currently support a "NodePort" type of ingress
	            local nodep_json=$endpoint_run_dir/$name-nodep.json
	            echo name: $name
	            echo ports: $ports
	            echo '{' >$nodep_json
                echo '    "apiVersion": "v1",' >>$nodep_json
                echo '    "kind": "Service",' >>$nodep_json
                echo '    "metadata": {' >>$nodep_json
                echo '        "name": "rickshaw-'$name'-nodeport"' >>$nodep_json
                echo '    },' >>$nodep_json
                echo '    "spec": {' >>$nodep_json
                echo '        "type": "NodePort",' >>$nodep_json
                echo '        "ports": [' >>$nodep_json
	            local count=1
	            local port_list=""
	            for port in $ports; do
		            if [ $count -gt 1 ]; then
                        port_list+=", $port"
                        echo '            ,{' >>$nodep_json
		            else
                        port_list="$port"
                        echo '            {' >>$nodep_json
		            fi
                    echo '                "name": "port-'$port'",' >>$nodep_json
                    echo '                "nodePort": '$port',' >>$nodep_json
                    echo '                "port": '$port',' >>$nodep_json
                    echo '                "protocol": "TCP",' >>$nodep_json
                    echo '                "targetPort": '$port >>$nodep_json
                    echo '            }' >>$nodep_json
		            let count=$count+1
                done
                echo '        ]' >>$nodep_json
                echo '    }' >>$nodep_json
                echo '}' >>$nodep_json
                cat "$nodep_json" | ssh $k8s_user@$k8s_host "kubectl create -f -" >"$endpoint_run_dir/create-svc-nodeport-$name.txt"
	            local endp_nodep_json=$endpoint_run_dir/$name-nodeport-endpoint.json
	            echo '{' >$endp_nodep_json
                echo '    "apiVersion": "v1",' >>$endp_nodep_json
                echo '    "kind": "Endpoints",' >>$endp_nodep_json
                echo '    "metadata": {' >>$endp_nodep_json
                echo '        "name": "rickshaw-'$name'-nodeport"' >>$endp_nodep_json
	            echo '    },' >>$endp_nodep_json
                echo '    "subsets": [{' >>$endp_nodep_json
                # We use the IP from the previously created service, not the pod's IP
                echo '        "addresses": [ { "ip": "'$svc_ip'" } ],' >>$endp_nodep_json
                echo '        "ports": [' >>$endp_nodep_json
	            count=1
	            for port in $ports; do
		            if [ $count -gt 1 ]; then
                        echo '            ,{' >>$endp_nodep_json
		            else
                        echo '            {' >>$endp_nodep_json
		            fi
                        echo '                "name": "port-'$port'", "port": '$port'}' >>$endp_nodep_json
		            let count=$count+1
	            done
                echo '        ]' >>$endp_nodep_json
                echo '    }]' >>$endp_nodep_json
                echo '}' >>$endp_nodep_json
                cat "$endp_nodep_json" | ssh $k8s_user@$k8s_host "kubectl create -f -" >"$endpoint_run_dir/create-endp-nodeport-$name.txt"
                # TODO: reassign $svc_ip to IP used from ingress method (we're assuming port numbers are unchanged)
                # ssh $k8s_user@$k8s_host "oc get nodes/worker000 -o wide" | grep worker000 | awk '{print $6}' | tr -d "\n" >>"$tx_msgs_dir/service-ip-$name.json"
                # ^^^ should not assume 'worker000' but find which worker this pod is on.
            fi # client is outside cluster
            # Now we can consruct a message to be sent to the client about the IP and ports for the server
            echo -n '{"recipient":{"type":"follower","id":"client-' >"$tx_msgs_dir/service-ip-$name.json"
	        echo $name | awk -F- '{print $2}' | tr -d "\n" >>"$tx_msgs_dir/service-ip-$name.json"
	        echo -n '"},"user-object":{"svc":{"ip": "'$svc_ip'", ' >>"$tx_msgs_dir/service-ip-$name.json"
	        echo '"ports": ['$port_list']}}}' >>"$tx_msgs_dir/service-ip-$name.json"
	    done 9< "$endpoint_run_dir/ports.txt"
    fi
    sleep 10 # why?
    echo "services:"
    ssh $k8s_user@$k8s_host "kubectl get svc"
    ssh $k8s_user@$k8s_host kubectl get svc -o yaml
    echo "endpoints:"
    ssh $k8s_user@$k8s_host "kubectl get endpoints"
    ssh $k8s_user@$k8s_host kubectl get endpoints -o yaml
}

function k8s_req_check() {
    k8s_kubeconfig=`ssh -o StrictHostKeyChecking=no $k8s_user@$k8s_host env | grep ^KUBECONFIG | awk -F"KUBECONFIG=" '{print $2}'`
    if [ -z "$k8s_kubeconfig" ]; then
        echo "[ERROR]KUBECONFIG on k8s host $k8s_host not defined"
        exit 1
    fi
    k8s_kubectl=`ssh -o StrictHostKeyChecking=no $k8s_user@$k8s_host kubectl 2>&1`
    if [ $? -gt 0 ]; then
        exit_error "Could not run kubectl on k8s host: $k8s_kubectl"
    fi
    # Validation returns what clients and servers would be used and the userenv
    if [ "$do_validate" == 1 ]; then
        echo_clients_servers
        echo "userenv $userenv"
        exit
    fi
}

function process_k8s_opts() {
    local endpoint_opts="$1"
    for opt in `echo $endpoint_opts | sed -e 's/,/ /g'`; do
        arg=`echo $opt| awk -F: '{print $1}'`
        # The $val may have : in it, so don't use awk to get only the second field
        val=`echo $opt | sed -e s/^$arg://`
        case "$arg" in
            client|server|clients|servers)
                addto_clients_servers "$arg" "$val"
                ;;
            host)
                k8s_host=$val
                ;;
            user)
                k8s_user=$val
                ;;
            userenv)
                userenv=$val
                ;;
            hostNetwork)
                hostNetwork="$val"
                ;;
            nodeSelector)
                # nodeSelector is per pod:
                # option format::  nodeSelector:<pod-name>:<full-path-to-json-with-nodeSelector>
                # json file example (note no outer {}'s)
                # "nodeSelector": {
                #    "kubernetes.io/hostname": "worker000"
                # }
                #TODO: validate correct format of <client-server-label>:<path-to-file>
                name=`echo $val | awk -F: '{print $1}'`
                file=`echo $val | awk -F: '{print $2}'`
                if [ ! -z "$file" -o -e $file ]; then
                    nodeSelector[$name]=`cat $file`
                else
                    exit_error "Could not find file $file"
                fi
                ;;
            securityContext)
                if [ ! -z "$val" -a -e $val ]; then
                    securityContext=`cat $val`
                else
                    exit_error "Could not find securityContext file '$val'"
                fi
                ;;
            resources)
                if [ ! -z "$val" -a -e "$val" ]; then
                    resources=`cat $val`
                else
                    exit_error "Could not find resources file '$val'"
                fi
                ;;
            *)
                if echo $arg | grep -q -- "="; then
                    echo "You can't use a \"=\" for assignment in endpoint options"
                    echo "You must use \":\", like `echo $arg | sed -e 's/=/:/'`"
                fi
                exit_error "k8s endpoint option [$arg] not supported"
                ;;
        esac
    done
}

function build_pod_spec() {
    local name=$1; shift
    local type=$1; shift
    local dir=$1; shift
    local host=$1; shift
    local json="$dir/$name.json"

    echo "{" >$json
    echo "  \"apiVersion\": \"v1\"," >>$json
    echo "  \"kind\": \"Pod\"," >>$json
    echo "  \"metadata\": {" >>$json
    echo "    \"name\": \"$pod_prefix-$name\"" >>$json
    echo "  }," >>$json
    echo "  \"spec\": {" >>$json
    echo "    \"restartPolicy\": \"Never\"," >>$json
    set +u
    if [ "$type" == "cs" -a ! -z "${nodeSelector[$name]}" ]; then
        echo -e "    ${nodeSelector[$name]}," >>$json
    fi
    set -u
    if [ "$type" == "cs" -a ! -z "$hostNetwork" -a "$hostNetwork" == "1" ]; then
        echo "    \"hostNetwork\": true," >>$json
    fi
    if [ "$type" == "master" ]; then
        echo '    "tolerations": [' >>$json
        echo '        {' >>$json
        echo '            "key": "node-role.kubernetes.io/master",' >>$json
        echo '            "effect": "NoSchedule"' >>$json
        echo '        }' >>$json
        echo '    ],' >>$json
    fi
    if [ "$type" == "worker" -o "$type" == "master" ]; then
        echo "    \"nodeSelector\": {" >>$json
        echo "        \"kubernetes.io/hostname\": \"$host\"" >>$json
        echo "    }," >>$json
        echo "    \"hostPID\": true," >>$json
        echo "    \"hostNetwork\": true", >>$json
        echo "    \"hostIPC\": true," >>$json
    fi
    echo "    \"containers\": [" >>$json
    echo "      {" >>$json
    echo "        \"name\": \"$name\"," >>$json
    echo "        \"image\": \"$image\"," >>$json
    echo "        \"imagePullPolicy\": \"Always\"," >>$json
    echo "        \"env\": [" >>$json
    echo "          {" >>$json
    echo "            \"name\": \"rickshaw_host\"," >>$json
    echo "            \"value\": \"$hostname\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"base_run_dir\"," >>$json
    echo "            \"value\": \"$base_run_dir\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"cs_label\"," >>$json
    echo "            \"value\": \"$name\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"endpoint_run_dir\"," >>$json
    echo "            \"value\": \"/endpoint-run\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"roadblock_server\"," >>$json
    echo "            \"value\": \"$rb_server\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"roadblock_passwd\"," >>$json
    echo "            \"value\": \"flubber\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"roadblock_id\"," >>$json
    echo "            \"value\": \"$rb_id\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"ssh_id\"," >>$json
    printf "            \"value\": \"" >>$json
    sed -z 's/\n/\\n/g' $config_dir/rickshaw_id.rsa >>$json
    echo "\"" >>$json
    echo "      }" >>$json
    let count=$count+1
    echo "    ]" >>$json
    if [ "$type" == "worker" -o "$type" == "master" ]; then
        echo '       ,"volumeMounts": [' >>$json
        echo '          { "mountPath": "/var/run",' >>$json
        echo '            "name": "hostfs-run"' >>$json
        echo '          }' >>$json
        echo "        ]" >>$json
    fi
    if [ "$type" == "worker" -o "$type" == "master" ]; then
        echo "        ,\"securityContext\": {" >>$json
        echo "          \"privileged\": true" >>$json
        echo "        }" >>$json 
    else
        if [ ! -z "$securityContext" ]; then
            echo -e ",$securityContext" >>$json
        fi
        if [ ! -z "$resources" ]; then
            echo -e ",$resources" >>$json
        fi
    fi
    echo "      }" >>$json
    echo "    ]" >>$json
    if [ "$type" == "worker" -o "$type" == "master" ]; then
        echo '       ,"volumes": [' >>$json
        echo '          { "name": "hostfs-run",' >>$json
        echo '            "hostPath": {' >>$json
        echo '              "path": "/var/run",' >>$json
        echo '              "type": "Directory"' >>$json
        echo '            }' >>$json
        echo '          }' >>$json
        echo '        ]' >>$json
    fi
    echo "  }" >>$json
    echo "}" >>$json
}

function create_pods() {
    typeset -n ref1=$1; shift # caller-provided variable name (call-by-reference)
    ref1=""
    local type="$1"; shift
    # remaining args are pod-names (for client-server pods) or worker/master node names
    local dir="$endpoint_run_dir/$type-pod-objects"
    local pods=""
    if [ -z "$*" ]; then
	    if [ "$type" == "master" -o "$type" == "worker" ]; then
            echo "The list of nodes for tool-pods for type $type is empty"
            echo "Something may be wrong in detecting these nodes"
        else
            exit_error "You must request one or more pods to create"
        fi
    fi
    mkdir -p "$dir"
    local count=1
    local pods_to_create=""
    while [ $# -gt 0 ]; do
        local name="$1"; shift
	    echo "create_pods: working on [$name]"
	    local host=""
	    if [ "$type" == "master" -o "$type" == "worker" ]; then
	        host="$name"
	        echo "because this is a tool pod, changing name from $name to..."
	        name="$type-$count"
	        echo "$name"
            let count=$count+1
	    fi
        pods_to_create+=" $name"
    done
    delete_pods $pods_to_create
    local this_pod
    for this_pod in $pods_to_create; do
        #echo "about to delete $name"
        #delete_pods "$name"
        echo build_pod_spec "$this_pod" "$type" "$dir" "$host"
        build_pod_spec "$this_pod" "$type" "$dir" "$host"
        if [ -e "$dir/$this_pod.json" ]; then
            # TODO: the exit code does not work here, need to find a way to have it work
            cat "$dir/$this_pod.json" | ssh $k8s_user@$k8s_host "kubectl create -f - 2>&1" >"$endpoint_run_dir/create-pod-output-$this_pod.txt"
            if [ $? -gt 0 ]; then
                exit_error "Failed to create pod $this_pod"
            fi
            pods+=" $this_pod"
        else
            exit_error "Could not find $dir/$this_pod.json to create pod: $create_output"
        fi
    done
    ssh $k8s_user@$k8s_host kubectl get pods 2>&1 >"$endpoint_run_dir/post-create-get-pods.txt"
    ref1="$pods"
}

function verify_pods_running() {
    typeset -n ref1=$1; shift # caller-provided variable name (call-by-reference)
    ref1=""
    local kubectl_get_pods="$endpoint_run_dir/kubectl-get-pods.txt"
    declare -A unverified_pods=()
    declare -A verified_pods=()
    if [ -z "$1" ]; then
        exit_error "You must provide at least 1 pod to verify"
    fi
    while [ $# -gt 0 ]; do
        unverified_pods[$1]=1; shift
    done
    local num_pods=${#unverified_pods[@]}
    local count=0
    local max_attempts=18
    local abort=0
    local num_nonzero_exit=0
    local max_nonzero_exit=3
    until [ ${#unverified_pods[@]} -eq 0 -o $count -gt $max_attempts -o $abort -gt 0 ]; do
        sleep 5
        ssh $k8s_user@$k8s_host kubectl get pods -o wide | grep $pod_prefix >$kubectl_get_pods
        rc=$?
        if [ $rc -gt 0 ]; then
            let num_nonzero_exit=$num_nonzero_exit+1
            if [ $num_nonzero_exit -gt $max_nonzero_exit ]; then
                exit_error "kubectl-get-pods returns non-zero more than $max_nonzero_exit times, exiting"
            fi
        fi
        echo "kubectl get pods:"
        cat $kubectl_get_pods
        while read line; do
            echo "got this line: $line"
            local this_status=`echo $line | awk '{print $3}'`
            local this_pod=`echo $line | awk '{print $1}' | sed -e s/^$pod_prefix-//`
            local node=`echo $line | awk '{print $7}'`
            if echo "$this_status" | grep -q -i error; then
                # If just 1 pod is in error bail immediately
                abort=1
                echo "Pod $this_pod has this error: $this_status"
                echo "Getting 'describe pod' for $pod_prefix-$this_pod"
                ssh $k8s_user@$k8s_host kubectl describe pod $pod_prefix-$this_pod >"$endpoint_run_dir/kubectl-describe-pod-$this_pod.txt"
                break
            fi
            if [ "$this_status" == "Running" ]; then
                verified_pods[$this_pod]="$node"
                unset unverified_pods[$this_pod]
            fi
        done <$kubectl_get_pods
        let count=$count+1
    done
    if [ $abort -eq 1 -o $count -gt $max_attempts ]; then
        #TODO: send abort signal for endpoint-deploy roadblock
        echo "abort: $abort count: $count"
        exit_error "Failed to verify pods are running"
    fi
    declare -A nodes
    for i in ${verified_pods[@]}; do
        nodes[$i]=1
    done
    # var is assigned a space-separated list of nodes
    ref1="${!nodes[@]}"
}

function get_pod_logs() {
    if [ -z "$1" ]; then
        exit_error "get_pod_logs(): at least 1 pod must be provided"
    fi
    while [ $# -gt 0 ]; do
        local name="$1"; shift
        echo "Getting logs from pod $name"
        pod_name="rickshaw-$name"
        ssh $k8s_user@$k8s_host kubectl logs $pod_name >"$client_server_logs_dir/$name.txt"
    done
}

function delete_pods() {
    if [ -z "$1" ]; then
        exit_error "delete_pods(): at least 1 pod must be provided"
    fi
    local pods_to_delete=""
    while [ $# -gt 0 ]; do
        local name="$1"; shift
        echo "checking for existing pod $name with prefix $pod_prefix-"
        local existing_pod="`ssh $k8s_user@$k8s_host kubectl get pods | grep "^$pod_prefix-$name " | awk '{print $1}'`"
        if [ ! -z "$existing_pod" ]; then
            echo "delete_pods(): found $name"
            pods_to_delete+=" $pod_prefix-$name"
        fi
    done
    if [ ! -z "$pods_to_delete" ]; then
        echo "going to bulk-delete these pods: $pods_to_delete"
        local delete_output=`ssh $k8s_user@$k8s_host "kubectl delete pod $pods_to_delete 2>&1"`
        if [ $? -gt 0 ]; then
            exit_error "Error deleting pod $existing_pod: $delete_output"
        fi
    fi
}

function delete_old_pods() {
    local pods=`ssh $k8s_user@$k8s_host kubectl get pods -o wide | grep $pod_prefix | awk '{print $1}' | sed -e s/$pod_prefix-// | tr '\n' ' '`
    if [ ! -z "$pods" ]; then
        echo "Going to delete these old pods: $pods"
        delete_pods $pods
    else
        echo "No old pods to delete"
    fi
}

function get_k8s_config() {
    local kubectl_nodes_json="$endpoint_run_dir/kubectl-get-nodes.json"
    local kubectl_nodes_stderr="$endpoint_run_dir/kubectl-get-nodes.stderr"
    local k8s_nodes=`ssh -o StrictHostKeyChecking=no $k8s_user@$k8s_host kubectl get nodes`
    ssh $k8s_user@$k8s_host kubectl get nodes -o json >$kubectl_nodes_json 2>$kubectl_nodes_stderr
    local nr_nodes=`jq -r '.items | length' $kubectl_nodes_json`
    local masters=""
    local workers=""
    local node=""
    for node in `seq 0 $(expr $nr_nodes - 1)`; do
        local name=`jq -r '.items['$node'] | .metadata.name' $kubectl_nodes_json`
        if [ "$(jq -r '.items['$node'] | .metadata.labels | has("node-role.kubernetes.io/worker")' $kubectl_nodes_json)" == "true" ]; then
            workers="$workers $name"
        fi
        if [ "$(jq -r '.items['$node'] | .metadata.labels | has("node-role.kubernetes.io/master")' $kubectl_nodes_json)" == "true" ]; then
            masters="$masters $name"
        fi
    done
    echo "$workers" >"$endpoint_run_dir/worker-nodes.txt"
    echo "$masters" >"$endpoint_run_dir/master-nodes.txt"
}

process_opts "$@"
process_k8s_opts "$endpoint_opts"
init_common_dirs
k8s_req_check
base_req_check
get_k8s_config
delete_old_pods
echo "This endpoint to run these clients: ${clients[@]}"
echo "This endpoint to run these servers: ${servers[@]}"
create_pods cs_pods cs ${clients[@]} ${servers[@]}
echo "These client pods were created: $cs_pods"
verify_pods_running active_worker_nodes $cs_pods
echo "These nodes are hosting the client-server pods: $active_worker_nodes"
echo "Working on creating worker-tool pods"
create_pods worker_tool_pods worker $active_worker_nodes
echo "These worker-tool pods were created: $worker_tool_pods"
verify_pods_running tool_worker_nodes $worker_tool_pods
echo "These nodes are hosting the worker-tool pods: $tool_worker_nodes"
master_nodes=`cat "$endpoint_run_dir/master-nodes.txt"`
echo "These nodes are masters: $master_nodes"
echo "Working on creating these master-tool pods"
create_pods master_tool_pods master $master_nodes
echo "These master-tool pods were created: $master_tool_pods"
verify_pods_running tool_master_nodes $master_tool_pods
echo "These nodes are hosting the master-tool pods: $master_nodes"
process_prebench_roadblocks $worker_tool_pods $master_tool_pods
process_bench_roadblocks k8s
process_postbench_roadblocks $worker_tool_pods $master_tool_pods
get_pod_logs $worker_tool_pods $master_tool_pods $cs_pods
delete_pods $worker_tool_pods $master_tool_pods $cs_pods
process_final_roadblocks
