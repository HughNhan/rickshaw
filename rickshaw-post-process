#!/usr/bin/perl
# -*- mode: perl; indent-tabs-mode: t; perl-indent-level: 4 -*-
# vim: autoindent tabstop=4 shiftwidth=4 expandtab softtabstop=4 filetype=perl
#
# Author: Andrew Theurer
#
# Rickshaw will run a benhcmark for you.  Please see README.md for instructions.

use strict;
use warnings;
use Cwd;
use Data::UUID;
use File::pushd;
use File::Basename;
use File::Temp qw(tempdir);
use File::Copy;
use File::Path qw(make_path);
use JSON::XS;
use Data::Dumper;
my $ug = Data::UUID->new;
my $debug = 1;
my %run; # A multi-dimensional, nested hash, schema TBD
         # This hash documents what was run.

my $run_dir;
my $run_file;    # 'rickshaw-run.json' containing all configuration data
                 # (generated by 'rickshaw-run' once a run is complete)
my $result_file; # 'rickshaw-result.json' containing all configuration and result data
                 # (generated by this script)

sub usage {
    print "\nusage:\n\n";
    print "--run-dir  Directory where result data is located for a previous 'rickshaw-run'\n";
}

sub debug_log {
    if ($debug) {
        print "[DEBUG]" . shift;
    }
}

sub put_json_file {
    my $filename = shift;
    my $json_ref = shift;
    my $coder = JSON::XS->new->canonical->pretty;
    debug_log(sprintf "trying to write [%s]\n", $filename);
    my $json_text = $coder->encode($json_ref);
    open(JSON_FH, ">" . $filename) || die("Could not open file $filename\n");
    printf JSON_FH "%s", $json_text;
    close JSON_FH;
}

sub get_json_file {
    my $filename = shift;
    my $coder = JSON::XS->new;
    debug_log(sprintf "trying to open [%s]\n", $filename);
    open(JSON_FH, $filename) || die("Could not open file $filename\n");
    my $json_text = "";
    while ( <JSON_FH> ) {
        $json_text .= $_;
    }
    close JSON_FH;
    my $perl_scalar = $coder->decode($json_text) || die "Could not read JSON";
    return $perl_scalar;
}

# This will consolidate chronologically sequential metric samples with same
# value, and if samples have no 'begin' a timestamp, it will be derived.
sub dedup_metric {
    my $metric_ref = shift;
    my $count = 0;
    my $num_samples = scalar @{ $$metric_ref{'data'} };
    return if ($num_samples == 0);
    my $native_interval = $$metric_ref{'data'}[1]{'end'} - $$metric_ref{'data'}[0]{'end'};
    for (my $i = scalar @{ $$metric_ref{'data'} } - 1; $i >= 0; $i--) {
        my $this_value = $$metric_ref{'data'}[$i]{'value'};
        # If 'begin' is missing or the previous sample has the same value as the current sample,
        # search backwards until we find an earlier sample that has a different value from the
        # current one.
        if (! defined $$metric_ref{'data'}[$i]{'begin'} or
            $$metric_ref{'data'}[$i - 1]{'vaule'} == $this_value) {
            # Need to find a "begin" based on earlier samples
            my $look_back = 0;
            while ($i - $look_back >= 0 and 
                   $$metric_ref{'data'}[$i - $look_back]{'value'} == $this_value) {
                $look_back++;
            }
            if ($i - $look_back >= 0) {
                $$metric_ref{'data'}[$i]{'begin'} = $$metric_ref{'data'}[$i - $look_back]{'end'} + 1;
            } else {
                #$i - $look_back + 1, $native_interval;
                $$metric_ref{'data'}[$i]{'begin'} = $$metric_ref{'data'}[0]{'end'} - $native_interval + 1;
            }
            if ($look_back > 1) { # deduping 1 or more samples
                splice @{ $$metric_ref{'data'} }, $i - $look_back + 1, $look_back - 1;
                $i -= $look_back + 1; # Adjust the loop variable since the array is shortened
            }
        }
    }
}

# Process the cmdline params
while (scalar @ARGV > 0) {
    my $p = shift @ARGV;
    debug_log(sprintf "processing \@ARGV, param: [%s]\n", $p);
    my $arg;
    my $val;

    if ( $p =~ /^\-\-(\S+)/ ) {
        $arg = $1;
        if ( $arg =~ /^(\S+)=(.*)/ ) { # '--arg=val'
            $arg = $1;
            $val = $2;
        } else { # '--arg val'
            $val = shift @ARGV;
        }
    } else {
        print "[ERROR]malformed cmdline parameter: %s\n";
        usage;
        exit 1;
    }
    debug_log(sprintf "processing \@ARGV, arg is: [%s], val is: [%s]\n", $arg, $val);
    if ($arg =~ /^help$/) {
        usage;
        exit 0;
    } elsif ($arg =~ /^run-dir$/) {
        debug_log(sprintf "argument: [%s]\n", $arg);
        $run_dir = $val;
    } else {
        printf "[ERROR]argument not valid: [%s]\n", $arg;
        usage;
        exit 1;
    }
}

# Ensure the run-dir hase absolute path
{
    my $dir = pushd($run_dir);
    debug_log(sprintf "pushd to [%s]\n", $run_dir);
    my $cwd = getcwd();
    debug_log(sprintf "cwd [%s]\n", $cwd);
    $run_dir = $cwd;
}

# Load the existing rickshaw-run.json
$run_file = $run_dir . "/rickshaw-run.json";
if (-e $run_file) {
    printf "opening %s\n", $run_file;
    my $run_ref = get_json_file($run_file);
    %run = %{ $run_ref };
    # TODO checks for minimum fileds for valid run
}

# Benchmark-specific post-processors convert benchmark-native data into a common JSON
# format, but this data is still per-client or per-server, as most of these benchmarks
# do not understand (or aware) of multiple clients/servers.  This post-processing takes
# the benchmark-specific post-processed data and aggregates it, as well as creating a
# hierarchcal JSON to organize by iteration -> sample -> period -> metric.
print "Waiting for consolidation of per-client/server data into sample data to complete\n";
for (my $i = 1; $i <= scalar @{ $run{'iterations'} }; $i++) {
    my $iter_array_idx = $i -1;
    my @samples;
    for (my $s = 1; $s <= $run{'num-samples'}; $s++) {
        my %sample; # sample data from all clients/servers
        my @cons_periods; # consolidated periods across clients/servers get merged here
        my $samp_dir = $run_dir . "/iteration-" . $i . "/sample-" . $s;
        opendir(my $samp_dh, $samp_dir);
        my @cs_names = grep(/^(clients|servers)$/, readdir($samp_dh));
        for my $cs_name (@cs_names) { 
            my $cs_name_dir = $samp_dir . "/" . $cs_name;
            opendir(my $cs_name_dh, $cs_name_dir);
            my @cs_ids = grep(/^(\d+)$/, readdir($cs_name_dh));
            for my $cs_id (@cs_ids) {
                my $cs_id_dir = $cs_name_dir . "/" . $cs_id;
                my $data_file = $cs_id_dir . "/" . "post-process-data.json";
                if (-e $data_file) {
                    my $data_ref = get_json_file($data_file);
                    my %data = %$data_ref;
                    if (defined $data{'periods'}) {
                        for (my $k = 0; $k < scalar @{ $data{'periods'} }; $k++) {
                            my $period_name = $data{'periods'}[$k]{'name'};
                            my $cons_period_id;
                            for (my $cons_id = 0; $cons_id < scalar @cons_periods; $cons_id++) {
                                if ($cons_periods[$cons_id]{'name'} eq $period_name) {
                                    $cons_period_id = $cons_id;
                                    last;
                                }
                            }
                            for my $metric (@{ $data{'periods'}[$k]{'metrics'} }) {
                                # Add the client info to the metric desc
                                $$metric{'names'}{'client-id'} = $cs_id;
                                $$metric{'desc'}{'name-format'} = '%client-id%' . "-" .
                                                                 $$metric{'desc'}{'name-format'};
                                if (! defined $cons_period_id) {
                                    my @metrics;
                                    my %period = ('name' => $period_name, 'metrics' => \@metrics);
                                    push(@cons_periods, \%period);
                                    $cons_period_id = scalar @cons_periods - 1;
                                }
                                dedup_metric($metric);
                                push(@{ $cons_periods[$cons_period_id]{'metrics'} }, $metric);
                            }
                        }
                    }
                }
            }
        }
        $sample{'periods'} = \@cons_periods;
        push(@samples, \%sample);
    }
    $run{'iterations'}[$iter_array_idx]{'samples'} = \@samples;
}
print "Consolidation complete\n";

put_json_file($run_dir . "/rickshaw-result.json", \%run);
