#!/usr/bin/perl
# -*- mode: perl; indent-tabs-mode: t; perl-indent-level: 4 -*-
# vim: autoindent tabstop=4 shiftwidth=4 expandtab softtabstop=4 filetype=perl
#
# Author: Andrew Theurer
#
# Rickshaw will run a benhcmark for you.  Please see README.md for instructions.

use strict;
use warnings;
use Cwd;
use Data::UUID;
use File::pushd;
use File::Basename;
use File::Temp qw(tempdir);
use File::Copy;
use File::Path qw(make_path);
use JSON::XS;
use JSON::Validator;
use Data::Dumper;
use IO::Compress::Xz;
use IO::Uncompress::UnXz;

my $ug = Data::UUID->new;
my $debug = 0;
my %run; # A multi-dimensional, nested hash, schema TBD
         # This hash documents what was run.

my $base_run_dir;
my $run_file;    # 'rickshaw-run.json' containing all configuration data
                 # (generated by 'rickshaw-run' once a run is complete)
my $result_file; # 'rickshaw-result.json' containing all configuration and result data
                 # (generated by this script)

sub usage {
    print "\nusage:\n\n";
    print "--base-run-dir  Directory where result data is located for a previous 'rickshaw-run'\n";
}

sub debug_log {
    if ($debug) {
        print "[DEBUG]" . shift;
    }
}

sub put_json_file {
    my $filename = shift;
    chomp $filename;
    my $json_ref = shift;
    my $schema_filename = shift;
    my $coder = JSON::XS->new->canonical->pretty;
    if (defined $schema_filename and -e $schema_filename) {
        chomp $schema_filename;
        my $jv = JSON::Validator->new;
	my $schema_fh = new IO::Uncompress::UnXz $schema_filename, Transparent => 1 || die "Could not open file " . $schema_filename;
        my $json_schema_text;
        while ( <$schema_fh> ) {
            $json_schema_text .= $_;
        }
        close($schema_fh);
        chomp $json_schema_text;
        $jv->schema($json_schema_text);
        debug_log(sprintf "Going to validate schema with [%s]\n", $schema_filename);
        my @errors = $jv->validate($json_ref);
        if (scalar @errors >  0) {
            printf "Validation errors for file %s with schema %s:\n", $filename, $schema_filename;
            print Dumper \@errors;
            exit 1;
        }
    }
    debug_log(sprintf "trying to write [%s]\n", $filename);
    my $json_text = $coder->encode($json_ref);
    my $json_fh;
    if ($filename =~ /xz$/) {
	$json_fh = new IO::Compress::Xz "$filename" || die("Could not open $filename.xz for writing\n");
    } else {
	open($json_fh, ">", $filename);
    }
    printf $json_fh "%s", $json_text;
    close($json_fh);
}

sub get_json_file {
    my $filename = shift;
    chomp $filename;
    my $schema_filename = shift;
    my $coder = JSON::XS->new;
    debug_log(sprintf "trying to open [%s]\n", $filename);
    my $log_fh = new IO::Uncompress::UnXz $filename, Transparent => 1 || die "Could not open file " . $filename;
    my $json_text = "";
    while ( <$log_fh> ) {
        $json_text .= $_;
    }
    close($log_fh);
    chomp $json_text;
    my $json_ref = $coder->decode($json_text) || die "Could not read JSON";
    if (defined $schema_filename and -e $schema_filename) {
        chomp $schema_filename;
        my $jv = JSON::Validator->new;
	my $schema_fh = new IO::Uncompress::UnXz $schema_filename, Transparent => 1 || die "Could not open file " . $schema_filename;
        my $json_schema_text;
        while ( <$schema_fh> ) {
            $json_schema_text .= $_;
        }
        close($schema_fh);
        chomp $json_schema_text;
        $jv->schema($json_schema_text);
        my @errors = $jv->validate($json_ref);
        if (scalar @errors >  0) {
            printf "Validaton errors for file %s with schema %s:\n", $filename, $schema_filename;
            print Dumper \@errors;
            exit 1;
        }
    }
    return $json_ref;
}

# This will consolidate chronologically sequential metric samples with same
# value, and if samples have no 'begin' a timestamp, it will be derived.
sub dedup_metric {
    my $metric_ref = shift;
    my $count = 0;
    my $num_samples = scalar @{ $$metric_ref{'data'} };
    my $first_begin;
    my $last_end;
    return (-1, -1) if ($num_samples == 0);
    if (! defined $$metric_ref{'data'}[1]{'end'}) {
        print "[ERROR]could not find second sample for metric\n";
        print Dumper $$metric_ref{'desc'};
        print Dumper $$metric_ref{'names'};
        return (-1, -1);
    }
    my $native_interval = $$metric_ref{'data'}[1]{'end'} - $$metric_ref{'data'}[0]{'end'};
    for (my $i = scalar @{ $$metric_ref{'data'} } - 1; $i >= 0; $i--) {
        my $this_value = $$metric_ref{'data'}[$i]{'value'};
        # If 'begin' is missing or the previous sample has the same value as the current sample,
        # search backwards until we find an earlier sample that has a different value from the
        # current one.
        if (! defined $$metric_ref{'data'}[$i]{'begin'} or
            $$metric_ref{'data'}[$i - 1]{'vaule'} == $this_value) {
            # Need to find a "begin" based on earlier samples
            my $look_back = 0;
            while ($i - $look_back >= 0 and 
                   $$metric_ref{'data'}[$i - $look_back]{'value'} == $this_value) {
                $look_back++;
            }
            if ($i - $look_back >= 0) {
                $$metric_ref{'data'}[$i]{'begin'} = int $$metric_ref{'data'}[$i - $look_back]{'end'} + 1;
            } else {
                #$i - $look_back + 1, $native_interval;
                $$metric_ref{'data'}[$i]{'begin'} = int $$metric_ref{'data'}[0]{'end'} - $native_interval + 1;
            }
            if ($look_back > 1) { # deduping 1 or more samples
                splice @{ $$metric_ref{'data'} }, $i - $look_back + 1, $look_back - 1;
                $i -= ($look_back - 1); # Adjust the loop variable since the array is shortened
            }
        }
        if (! exists $$metric_ref{'data'}[$i]{'begin'}) {
            printf "ERROR: 'begin' for sample %d is missing\n", $i;
            printf "i: %d\n", $i;
            print Dumper $metric_ref;
            exit;
        } else {
            $$metric_ref{'data'}[$i]{'duration'} = int $$metric_ref{'data'}[$i]{'end'} -
                                                    $$metric_ref{'data'}[$i]{'begin'} + 1;
            if (! defined $first_begin or $$metric_ref{'data'}[$i]{'begin'} < $first_begin) {
                $first_begin = $$metric_ref{'data'}[$i]{'begin'};
            }
            if (! defined $last_end or $$metric_ref{'data'}[$i]{'end'} > $last_end) {
                $last_end = $$metric_ref{'data'}[$i]{'end'};
            }
        }
    }
    return ($first_begin, $last_end);
}


my $rickshaw_dir;
{
    # Get the absolute path of the rickshaw project directory
    my $dir = pushd(dirname($0));
    $rickshaw_dir = getcwd();
}
my $bench_metric_schema_file = $rickshaw_dir . "/schema/bench-metric.json";
my $run_schema_file = $rickshaw_dir . "/schema/run.json";
my $result_schema_file = $rickshaw_dir . "/schema/result.json";

# Process the cmdline params
while (scalar @ARGV > 0) {
    my $p = shift @ARGV;
    debug_log(sprintf "processing \@ARGV, param: [%s]\n", $p);
    my $arg;
    my $val;

    if ( $p =~ /^\-\-(\S+)/ ) {
        $arg = $1;
        if ( $arg =~ /^(\S+)=(.*)/ ) { # '--arg=val'
            $arg = $1;
            $val = $2;
        } else { # '--arg val'
            $val = shift @ARGV;
        }
    } else {
        print "[ERROR]malformed cmdline parameter: %s\n";
        usage;
        exit 1;
    }
    debug_log(sprintf "processing \@ARGV, arg is: [%s], val is: [%s]\n", $arg, $val);
    if ($arg =~ /^help$/) {
        usage;
        exit 0;
    } elsif ($arg =~ /^base-run-dir$/) {
        debug_log(sprintf "argument: [%s]\n", $arg);
        $base_run_dir = $val;
    } else {
        printf "[ERROR]argument not valid: [%s]\n", $arg;
        usage;
        exit 1;
    }
}

# Ensure the run-dir hase absolute path
{
    my $dir = pushd($base_run_dir);
    debug_log(sprintf "pushd to [%s]\n", $base_run_dir);
    my $cwd = getcwd();
    debug_log(sprintf "cwd [%s]\n", $cwd);
    $base_run_dir = $cwd;
}
my $run_dir = $base_run_dir . "/run";
my $iter_dir = $run_dir . "/iterations";

# Load the existing rickshaw-run.json
$run_file = $run_dir . "/rickshaw-run.json";
if (! -e $run_file) {
    $run_file = $run_dir . "/rickshaw-run.json.xz";
}
if (-e $run_file) {
    printf "opening %s\n", $run_file;
    my $run_ref = get_json_file($run_file, $run_schema_file);
    %run = %{ $run_ref };
    # TODO checks for minimum fileds for valid run
} else {
    printf "Could not find rickshaw-run.json in %s, exiting\n", $run_dir;
    exit 1;
}

# Benchmark-specific post-processors convert benchmark-native data into a common JSON
# format, but this data is still per-client or per-server, as most of these benchmarks
# do not understand (or aware) of multiple clients/servers.  This post-processing takes
# the benchmark-specific post-processed data and aggregates it, as well as creating a
# hierarchcal JSON to organize by iteration -> sample -> period -> metric.
print "Waiting for consolidation of per-client/server data into sample data to complete\n";
for (my $i = 1; $i <= scalar @{ $run{'iterations'} }; $i++) {
    my $iter_dh;
    my $this_iter_dir = $iter_dir . "/iteration-" . $i;
    opendir($iter_dh, $this_iter_dir);
    my @samp_dirs = grep(/^sample-\d+/, readdir($iter_dh));
    my $iter_array_idx = $i -1;
    my @samples;
    my $primary_metric;
    my $primary_period;
    for my $samp_dir (@samp_dirs) {
        my $samp_status = "pass";
        if ($samp_dir =~ /fail\d+/) {
            $samp_status = "fail"
        }
        my %sample; # sample data from all clients/servers
        $sample{'status'} = $samp_status;
        my @cons_periods; # consolidated periods across clients/servers get merged here
        my $this_samp_dir = $this_iter_dir . "/" .  $samp_dir;
        debug_log("Working on " . $this_samp_dir . "\n");
        opendir(my $samp_dh, $this_samp_dir);
        my @cs_names = grep(/^(client|server)$/, readdir($samp_dh));
        for my $cs_name (@cs_names) { 
            my $cs_name_dir = $this_samp_dir . "/" . $cs_name;
            opendir(my $cs_name_dh, $cs_name_dir);
            my @cs_ids = grep(/^(\d+)$/, readdir($cs_name_dh));
            for my $cs_id (@cs_ids) {
                my $cs_id_dir = $cs_name_dir . "/" . $cs_id;
                my $data_file = $cs_id_dir . "/" . "post-process-data.json";
		if (! -e $data_file) {
		    $data_file = $cs_id_dir . "/" . "post-process-data.json.xz";
		}
                if (-e $data_file) {
                    my $data_ref = get_json_file($data_file, $bench_metric_schema_file);
                    my %data = %$data_ref;
                    if (! defined $primary_metric and exists $data{'primary-metric'}) {
                        $primary_metric = $data{'primary-metric'};
                    }
                    if (! defined $primary_period and exists $data{'primary-period'}) {
                        $primary_period = $data{'primary-period'};
                    }
                    if (defined $data{'periods'}) {
                        for (my $k = 0; $k < scalar @{ $data{'periods'} }; $k++) {
                            my $period_name = $data{'periods'}[$k]{'name'};
                            my $cons_period_id;
                            for (my $cons_id = 0; $cons_id < scalar @cons_periods; $cons_id++) {
                                if ($cons_periods[$cons_id]{'name'} eq $period_name) {
                                    $cons_period_id = $cons_id;
                                    last;
                                }
                            }
                            for my $metric (@{ $data{'periods'}[$k]{'metrics'} }) {
                                # Add the client/server info to the metric desc
                                $$metric{'names'}{'cstype'} = $cs_name;
                                $$metric{'names'}{'csid'} = $cs_id;
                                if ($$metric{'desc'}{'name-format'} eq "") {
                                    $$metric{'desc'}{'name-format'} = '%cstype%-%csid%';
                                } else {
                                    $$metric{'desc'}{'name-format'} = '%cstype%-%csid%-' . $$metric{'desc'}{'name-format'};
                                }
                                if (! defined $cons_period_id) {
                                    my @metrics;
                                    my %period = ('name' => $period_name, 'metrics' => \@metrics);
                                    push(@cons_periods, \%period);
                                    $cons_period_id = scalar @cons_periods - 1;
                                }
                                ($cons_periods[$cons_period_id]{'begin'},
                                 $cons_periods[$cons_period_id]{'end'}) = dedup_metric($metric);
                                if ($cons_periods[$cons_period_id]{'begin'} > 0 and
                                    $cons_periods[$cons_period_id]{'end'} > 0) {
                                    push(@{ $cons_periods[$cons_period_id]{'metrics'} }, $metric);
                                }
                            }
                        }
                    }
                }
            }
        }
        $sample{'periods'} = \@cons_periods;
        push(@samples, \%sample);
    }
    $run{'iterations'}[$iter_array_idx]{'samples'} = \@samples;
    if (defined $primary_metric) {
        $run{'iterations'}[$iter_array_idx]{'primary-metric'} = $primary_metric;
    } else {
        printf "Warning: no primary-metric was found for %s\n", $this_iter_dir;
    }
    if (defined $primary_period) {
        $run{'iterations'}[$iter_array_idx]{'primary-period'} = $primary_period;
    } else {
        printf "Warning: no primary-period was found for %s\n", $this_iter_dir;
    }
}

# Next, any tool data found is added
my $tool_dir = $run_dir . "/tool-data";
opendir(TOOLDIR, $tool_dir);
my @collectors = grep(/\w+/, readdir(TOOLDIR));
for my $collector (@collectors) {
    my $collector_dir = $tool_dir . "/" . $collector;  # $run_dir/tool-data/[client|server|worker|master]
    opendir(COLLECTORDIR, $collector_dir);
    my @numbers = grep (/\d+/, readdir(COLLECTORDIR));
    for my $num (@numbers) {
        my $cd_id = $collector . "-" . $num;
        my $num_dir = $collector_dir . "/" . $num; # $run_dir/tool-data/[client|server|worker|master]/[0-N]
        opendir(NUMDIR, $num_dir);
        my @tools = grep(/\w+/, readdir(NUMDIR));
        for my $tool (@tools) {
            my $metric_data_file = $num_dir . "/" . $tool . "/metric-data.json";
	    if (! -e $metric_data_file) {
		$metric_data_file = $num_dir . "/" . $tool . "/metric-data.json.xz";
	    }
            if (-e $metric_data_file) {
                my $metrics_ref = get_json_file($metric_data_file);
                for my $metric_ref (@{ $metrics_ref }) {
                    # Add the client/server info to the metric desc
                    $$metric_ref{'names'}{'cstype'} = $collector;
                    $$metric_ref{'names'}{'csid'} = $num;
                    if ($$metric_ref{'desc'}{'name-format'} eq "") {
                        $$metric_ref{'desc'}{'name-format'} = '%cstype%-%csid%';
                    } else {
                        $$metric_ref{'desc'}{'name-format'} = '%cstype%-%csid%-' . $$metric_ref{'desc'}{'name-format'};
                    }
                    (my $begin, my $end) = dedup_metric($metric_ref);
                    if ($begin > 0 and $end > 0) {
                        push(@{ $run{'tool-data'} }, $metric_ref);
                    }
                }
            }
        }
    }
}

print "Consolidation complete\n";
delete $run{'rickshaw-run'};
$run{'rickshaw-result'}{'schema'}{'version'} = "2020.03.18";
put_json_file($run_dir . "/rickshaw-result.json.xz", \%run, $result_schema_file);
